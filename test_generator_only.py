"""
è¨€èªãƒ¢ãƒ‡ãƒ«å˜ä½“ã®ãƒ†ã‚¹ãƒˆ
RAGã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã€rerankã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã ã‘ã‚’ç¢ºèª
"""

import sys
import logging
from pathlib import Path
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# src/ ã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "src"))


def setup_logging():
    """ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


def test_raw_model():
    """transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç›´æ¥ä½¿ç”¨ã—ãŸæœ€å°é™ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("RAW ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ (transformersç›´æ¥ä½¿ç”¨)")
    print("=" * 60)

    model_name = "Qwen/Qwen2.5-0.5B-Instruct"  # æœ€è»½é‡ç‰ˆã§ãƒ†ã‚¹ãƒˆ

    print(f"\n[1] ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # pad_tokenè¨­å®š
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        print("  - pad_token ã‚’ eos_token ã«è¨­å®š")

    model = AutoModelForCausalLM.from_pretrained(model_name)
    device = torch.device("cpu")
    model.to(device)
    model.eval()
    print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\n")

    # è¶…ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = "æ±äº¬ã¯"
    print(f"[2] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: '{prompt}'")

    # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    print("[3] ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ä¸­...")
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    input_length = inputs["input_ids"].shape[1]
    print(f"  - å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {input_length}")

    # ç”Ÿæˆï¼ˆæœ€å°é™ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
    print("[4] ç”Ÿæˆä¸­ (max_new_tokens=10)...")
    try:
        with torch.no_grad():
            output_ids = model.generate(
                inputs["input_ids"],
                max_new_tokens=10,
                do_sample=False,
                pad_token_id=tokenizer.pad_token_id,
            )
        print("âœ“ ç”Ÿæˆå®Œäº†")
    except Exception as e:
        print(f"âœ— ç”Ÿæˆå¤±æ•—: {e}")
        return False

    # ãƒ‡ã‚³ãƒ¼ãƒ‰
    print("[5] ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­...")
    generated = tokenizer.decode(output_ids[0], skip_special_tokens=True)

    print("\n" + "=" * 60)
    print("çµæœ")
    print("=" * 60)
    print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ç”Ÿæˆçµæœ: {generated}")
    print("=" * 60)

    if len(generated) > len(prompt):
        print("\nâœ“ æˆåŠŸ: æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
        return True
    else:
        print("\nâœ— å¤±æ•—: æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return False


def test_generator_class():
    """QwenGeneratorã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("[STEP 2] QwenGenerator ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    from generator import QwenGenerator

    print("\n[1] QwenGeneratoråˆæœŸåŒ–ä¸­...")
    generator = QwenGenerator(model_name="Qwen/Qwen2.5-0.5B-Instruct")
    print("âœ“ åˆæœŸåŒ–å®Œäº†")

    # ãƒ€ãƒŸãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    contexts = [{"text": "ç¹”ç”°ä¿¡é•·ã¯æˆ¦å›½æ™‚ä»£ã®æ­¦å°†ã€‚", "article_title": "ãƒ†ã‚¹ãƒˆ", "chunk_id": 0}]

    question = "ç¹”ç”°ä¿¡é•·ã«ã¤ã„ã¦æ•™ãˆã¦"

    print(f"\n[2] è³ªå•: {question}")
    print("[3] å›ç­”ç”Ÿæˆä¸­...")

    try:
        answer = generator.generate_answer(question, contexts)

        print("\n" + "=" * 60)
        print("çµæœ")
        print("=" * 60)
        print(f"è³ªå•: {question}")
        print(f"å›ç­”: {answer}")
        print("=" * 60)

        if answer and len(answer) > 0:
            print("\nâœ“ æˆåŠŸ: QwenGeneratorãŒæ­£å¸¸ã«å‹•ä½œã—ã¾ã—ãŸ")
            return True
        else:
            print("\nâœ— å¤±æ•—: å›ç­”ãŒç©ºã§ã™")
            return False

    except Exception as e:
        print(f"\nâœ— ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    setup_logging()

    try:
        # STEP 1: RAWãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
        print("\n[STEP 1] transformersç›´æ¥ãƒ†ã‚¹ãƒˆ")
        success_raw = test_raw_model()

        if not success_raw:
            print("\nâŒ åŸºæœ¬çš„ãªç”ŸæˆãŒå‹•ä½œã—ã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç’°å¢ƒã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
            return 1

        print("\nâœ“ STEP 1 æˆåŠŸï¼")

        # STEP 2: QwenGeneratorã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ
        success_generator = test_generator_class()

        if not success_generator:
            print("\nâŒ QwenGeneratorã‚¯ãƒ©ã‚¹ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            return 1

        print("\n" + "=" * 60)
        print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
        print("=" * 60)
        print("âœ“ transformersç›´æ¥ãƒ†ã‚¹ãƒˆ: PASS")
        print("âœ“ QwenGeneratorã‚¯ãƒ©ã‚¹: PASS")
        print("\nRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’è©¦ã™æº–å‚™ãŒã§ãã¾ã—ãŸï¼")
        print("æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print('  python src/rag_wiki.py -q "ç¹”ç”°ä¿¡é•·ã«ã¤ã„ã¦æ•™ãˆã¦"')
        print("=" * 60)

        return 0

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 130
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
